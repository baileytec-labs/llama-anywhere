{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# A list of SageMaker instances\n",
    "sagemaker_instances = [\"ml.m5.large\", \"ml.m5.xlarge\", \"ml.m5.2xlarge\", \"ml.m5.4xlarge\"]\n",
    "\n",
    "# Create a Dropdown widget\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=sagemaker_instances,\n",
    "    description='Instances:',\n",
    ")\n",
    "\n",
    "# Display the dropdown\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This creates the endpoint with the appropriate permissions. Make sure you have the bucket created first.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "\n",
    "instance_type=dropdown.value\n",
    "\n",
    "\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "\n",
    "bucket_name = '<your-bucket-name>'  # replace with your bucket name\n",
    "role_name = 'SageMakerExecutionRole'  # replace with your preferred role name\n",
    "model_name = '<model-name>'\n",
    "image = '<account-id>.dkr.ecr.<region>.amazonaws.com/<image-name>:latest'\n",
    "endpoint_config_name = '<endpoint-config-name>'\n",
    "endpoint_name = '<endpoint-name>'\n",
    "client = boto3.client('sagemaker')\n",
    "\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName=role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"s3:*\",\n",
    "            \"Resource\": f\"arn:aws:s3:::{bucket_name}/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_policy_response = iam.create_policy(\n",
    "    PolicyName=f\"{role_name}Policy\",\n",
    "    PolicyDocument=json.dumps(policy_document)\n",
    ")\n",
    "\n",
    "iam.attach_role_policy(\n",
    "    RoleName=role_name,\n",
    "    PolicyArn=create_policy_response['Policy']['Arn']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "exec_role_arn=create_role_response['Role']['Arn']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "response = client.create_model(\n",
    "    ModelName=model_name,\n",
    "    PrimaryContainer={\n",
    "        'Image': image,\n",
    "        'Mode': 'SingleModel',\n",
    "    },\n",
    "    ExecutionRoleArn=exec_role_arn\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "response = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'default',\n",
    "            'ModelName': model_name,\n",
    "            'InitialInstanceCount': 1,\n",
    "            'InstanceType': instance_type,\n",
    "            'InitialVariantWeight': 1.0,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we define the functionality to \n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "\n",
    "def invoke_sagemaker_endpoint(endpoint_name, llama_args):\n",
    "    payload = {\n",
    "        'inference': True,\n",
    "        'args': llama_args\n",
    "    }\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json',\n",
    "    )\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "    return response_body\n",
    "\n",
    "def configure_sagemaker_endpoint(endpoint_name, llama_model_args):\n",
    "    payload = {\n",
    "        'configure': True,\n",
    "        'args': llama_model_args\n",
    "    }\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        Body=json.dumps(payload),\n",
    "        ContentType='application/json',\n",
    "    )\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "    return response_body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So now, if you'd like to use this, Once you've configured and deployed your environment:\n",
    "\"\"\"\n",
    "llama_model_args = {\n",
    "    \"bucket\":bucket_name,\n",
    "    \"key\":\"mymodel.bin\",\n",
    "    \"n_ctx\": 512,\n",
    "    \"n_parts\": -1,\n",
    "    \"n_gpu_layers\": 0,\n",
    "    \"seed\": 1337,\n",
    "    \"f16_kv\": True,\n",
    "    \"logits_all\": False,\n",
    "    \"vocab_only\": False,\n",
    "    \"use_mmap\": True,\n",
    "    \"use_mlock\": False,\n",
    "    \"embedding\": False,\n",
    "    \"n_threads\": None,\n",
    "    \"n_batch\": 512,\n",
    "    \"last_n_tokens_size\": 64,\n",
    "    \"lora_base\": None,\n",
    "    \"lora_path\": None,\n",
    "    \"low_vram\": False,\n",
    "    \"tensor_split\": None,\n",
    "    \"rope_freq_base\": 10000,\n",
    "    \"rope_freq_scale\": 1,\n",
    "    \"verbose\": False,\n",
    "}\n",
    "\n",
    "\n",
    "llama_args = {\n",
    "    \"prompt\": \"The quick brown fox\",\n",
    "    \"max_tokens\": 128,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_p\": 0.95,\n",
    "    \"logprobs\": None,\n",
    "    \"echo\": False,\n",
    "    \"stop\": [],\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"repeat_penalty\": 1.1,\n",
    "    \"top_k\": 40,\n",
    "    \"stream\": False,\n",
    "    \"tfs_z\": 1,\n",
    "    \"mirostat_mode\": 0,\n",
    "    \"mirostat_tau\": 5,\n",
    "    \"mirostat_eta\": 0.1,\n",
    "    \"model\": None,\n",
    "}\n",
    "\n",
    "configuration = configure_sagemaker_endpoint(endpoint_name,llama_model_args)\n",
    "inference = invoke_sagemaker_endpoint(endpoint_name,llama_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
